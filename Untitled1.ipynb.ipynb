{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2f83fe-5d99-4ccf-bf14-3373930d8f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Ratings:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# No need to include folder path since you're already inside it\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "print(\"Movies:\")\n",
    "print(movies.head())\n",
    "\n",
    "print(\"\\nRatings:\")\n",
    "print(ratings.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97accc8-40e0-44e0-a6be-ff866ef4c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data:\n",
      "   userId  movieId  rating  timestamp                        title  \\\n",
      "0       1        1     4.0  964982703             Toy Story (1995)   \n",
      "1       1        3     4.0  964981247      Grumpier Old Men (1995)   \n",
      "2       1        6     4.0  964982224                  Heat (1995)   \n",
      "3       1       47     5.0  964983815  Seven (a.k.a. Se7en) (1995)   \n",
      "4       1       50     5.0  964982931   Usual Suspects, The (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                               Comedy|Romance  \n",
      "2                        Action|Crime|Thriller  \n",
      "3                             Mystery|Thriller  \n",
      "4                       Crime|Mystery|Thriller  \n",
      "\n",
      "Missing values:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "title        0\n",
      "genres       0\n",
      "dtype: int64\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      " 4   title      100836 non-null  object \n",
      " 5   genres     100836 non-null  object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge ratings with movies on 'movieId'\n",
    "data = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "# Show the combined data\n",
    "print(\"Combined Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Summary of data\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935385e6-00cc-4abc-981d-b2ed8718040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c33973-e328-46f0-8f2e-099a973103ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'genres' column\n",
    "movies['genres'] = movies['genres'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e36af38-6e72-4a77-b0b7-ab3322dd7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fb4540-596b-47fa-983c-55d55f572ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b707d05d-927d-46a3-a0c5-225afc6c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.reset_index()\n",
    "indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c2b8d6-fdc8-41ca-8ab6-d17799fe913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf480ba-23c0-490f-b62d-82c0b75fa48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1706                                          Antz (1998)\n",
       "2355                                   Toy Story 2 (1999)\n",
       "2809       Adventures of Rocky and Bullwinkle, The (2000)\n",
       "3000                     Emperor's New Groove, The (2000)\n",
       "3568                                Monsters, Inc. (2001)\n",
       "6194                                     Wild, The (2006)\n",
       "6486                               Shrek the Third (2007)\n",
       "6948                       Tale of Despereaux, The (2008)\n",
       "7760    Asterix and the Vikings (AstÃ©rix et les Viking...\n",
       "8219                                         Turbo (2013)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Toy Story (1995)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b42ff4f-71f1-4387-860e-9289596a7b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Local\\Temp\\ipykernel_34932\\841623850.py\", line 1, in <module>\n",
      "    from surprise import Dataset, Reader, SVD\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\__init__.py\", line 6, in <module>\n",
      "    from .prediction_algorithms import (\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\__init__.py\", line 23, in <module>\n",
      "    from .algo_base import AlgoBase\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\algo_base.py\", line 8, in <module>\n",
      "    from .. import similarities as sims\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader, SVD\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\__init__.py:6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset_dir\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprediction_algorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     AlgoBase,\n\u001b[32m      8\u001b[39m     BaselineOnly,\n\u001b[32m      9\u001b[39m     CoClustering,\n\u001b[32m     10\u001b[39m     KNNBaseline,\n\u001b[32m     11\u001b[39m     KNNBasic,\n\u001b[32m     12\u001b[39m     KNNWithMeans,\n\u001b[32m     13\u001b[39m     KNNWithZScore,\n\u001b[32m     14\u001b[39m     NMF,\n\u001b[32m     15\u001b[39m     NormalPredictor,\n\u001b[32m     16\u001b[39m     Prediction,\n\u001b[32m     17\u001b[39m     PredictionImpossible,\n\u001b[32m     18\u001b[39m     SlopeOne,\n\u001b[32m     19\u001b[39m     SVD,\n\u001b[32m     20\u001b[39m     SVDpp,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\__init__.py:23\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`prediction_algorithms` package includes the prediction algorithms\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mavailable for recommendation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33;03m    co_clustering.CoClustering\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgoBase\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbaseline_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaselineOnly\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mco_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoClustering\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`surprise.prediction_algorithms.algo_base` module defines the base\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mclass :class:`AlgoBase` from which every single prediction algorithm has to\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03minherit.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mheapq\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m similarities \u001b[38;5;28;01mas\u001b[39;00m sims\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize_baselines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m baseline_als, baseline_sgd\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredictions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Prediction, PredictionImpossible\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\similarities.pyx:1\u001b[39m, in \u001b[36minit surprise.similarities\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Define a reader with the rating scale (in our dataset it's 0.5 to 5.0)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Load the data from the ratings dataframe\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data into training and test sets\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use SVD algorithm (one of the best collaborative filtering models)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b1602d-25b0-4d6c-9a44-53f8cdd97637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Local\\Temp\\ipykernel_34932\\841623850.py\", line 1, in <module>\n",
      "    from surprise import Dataset, Reader, SVD\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\__init__.py\", line 6, in <module>\n",
      "    from .prediction_algorithms import (\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\__init__.py\", line 23, in <module>\n",
      "    from .algo_base import AlgoBase\n",
      "  File \"C:\\Users\\DEEPAK REDDY\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\algo_base.py\", line 8, in <module>\n",
      "    from .. import similarities as sims\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader, SVD\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\__init__.py:6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset_dir\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprediction_algorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     AlgoBase,\n\u001b[32m      8\u001b[39m     BaselineOnly,\n\u001b[32m      9\u001b[39m     CoClustering,\n\u001b[32m     10\u001b[39m     KNNBaseline,\n\u001b[32m     11\u001b[39m     KNNBasic,\n\u001b[32m     12\u001b[39m     KNNWithMeans,\n\u001b[32m     13\u001b[39m     KNNWithZScore,\n\u001b[32m     14\u001b[39m     NMF,\n\u001b[32m     15\u001b[39m     NormalPredictor,\n\u001b[32m     16\u001b[39m     Prediction,\n\u001b[32m     17\u001b[39m     PredictionImpossible,\n\u001b[32m     18\u001b[39m     SlopeOne,\n\u001b[32m     19\u001b[39m     SVD,\n\u001b[32m     20\u001b[39m     SVDpp,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\__init__.py:23\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`prediction_algorithms` package includes the prediction algorithms\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mavailable for recommendation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33;03m    co_clustering.CoClustering\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgo_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgoBase\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbaseline_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaselineOnly\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mco_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoClustering\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`surprise.prediction_algorithms.algo_base` module defines the base\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mclass :class:`AlgoBase` from which every single prediction algorithm has to\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03minherit.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mheapq\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m similarities \u001b[38;5;28;01mas\u001b[39;00m sims\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize_baselines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m baseline_als, baseline_sgd\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredictions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Prediction, PredictionImpossible\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\surprise\\similarities.pyx:1\u001b[39m, in \u001b[36minit surprise.similarities\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Define a reader with the rating scale (in our dataset it's 0.5 to 5.0)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Load the data from the ratings dataframe\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data into training and test sets\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use SVD algorithm (one of the best collaborative filtering models)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41970aa-2ed9-41c0-8eab-e40e8cc5497b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m reader = Reader(rating_scale=(\u001b[32m0.5\u001b[39m, \u001b[32m5.0\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load the data from the ratings dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data_cf = Dataset.load_from_df(\u001b[43mratings\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33muserId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmovieId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m'\u001b[39m]], reader)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Split data into training and test sets\u001b[39;00m\n\u001b[32m     12\u001b[39m trainset, testset = train_test_split(data_cf, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Define a reader with the rating scale (in our dataset it's 0.5 to 5.0)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Load the data from the ratings dataframe\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data into training and test sets\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use SVD algorithm (one of the best collaborative filtering models)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3677ade0-56a9-4f3a-8133-951d5a332bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "RMSE: 0.8782\n",
      "RMSE: 0.878217952503371\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD  # You can also use other algorithms like KNNBasic, KNNWithZScore, etc.\n",
    "\n",
    "# Step 1: Load your ratings dataset\n",
    "ratings = pd.read_csv('ratings.csv')  # Replace with your actual file path\n",
    "\n",
    "# Step 2: Ensure the data has the columns 'userId', 'movieId', and 'rating'\n",
    "print(ratings.head())  # Optional: Check if data loaded correctly\n",
    "\n",
    "# Step 3: Create a Reader object for Surprise to interpret the data\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Step 4: Load the data into Surprise's Dataset object\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Apply a collaborative filtering algorithm (e.g., SVD)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Step 7: Evaluate the model on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Optionally, you can calculate RMSE or other metrics\n",
    "from surprise import accuracy\n",
    "print(\"RMSE:\", accuracy.rmse(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a32ea16-8b2d-45c6-94b6-44e528832db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8782\n",
      "RMSE: 0.878217952503371\n",
      "MAE:  0.6745\n",
      "MAE: 0.6744669693401719\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# You can also calculate MAE (Mean Absolute Error)\n",
    "mae = accuracy.mae(predictions)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e2c184-1ce0-4993-aecb-40f6e0b43926",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy\n\u001b[32m      5\u001b[39m reader = Reader(rating_scale=(\u001b[32m0.5\u001b[39m, \u001b[32m5.0\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m data_cf = Dataset.load_from_df(\u001b[43mratings\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33muserId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmovieId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m'\u001b[39m]], reader)\n\u001b[32m      8\u001b[39m trainset, testset = train_test_split(data_cf, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     10\u001b[39m model = SVD()\n",
      "\u001b[31mNameError\u001b[39m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "predictions = model.test(testset)\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25f9975-82fe-4396-98d5-36369a32eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e57cd03-2dcd-4392-be89-6f30b2158835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8769043170332599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "predictions = model.test(testset)\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10969897-f639-44f0-a6e8-9a2f5d48f6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>In the Name of the Father (1993)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Dr. Strangelove or: How I Learned to Stop Worr...</td>\n",
       "      <td>Comedy|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Philadelphia Story, The (1940)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Rear Window (1954)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>North by Northwest (1959)</td>\n",
       "      <td>Action|Adventure|Mystery|Romance|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Some Like It Hot (1959)</td>\n",
       "      <td>Comedy|Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Streetcar Named Desire, A (1951)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Good, the Bad and the Ugly, The (Buono, il bru...</td>\n",
       "      <td>Action|Adventure|Western</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "277                   Shawshank Redemption, The (1994)   \n",
       "413                   In the Name of the Father (1993)   \n",
       "474                                Blade Runner (1982)   \n",
       "602  Dr. Strangelove or: How I Learned to Stop Worr...   \n",
       "680                     Philadelphia Story, The (1940)   \n",
       "686                                 Rear Window (1954)   \n",
       "690                          North by Northwest (1959)   \n",
       "692                            Some Like It Hot (1959)   \n",
       "841                   Streetcar Named Desire, A (1951)   \n",
       "903  Good, the Bad and the Ugly, The (Buono, il bru...   \n",
       "\n",
       "                                        genres  \n",
       "277                                Crime|Drama  \n",
       "413                                      Drama  \n",
       "474                     Action|Sci-Fi|Thriller  \n",
       "602                                 Comedy|War  \n",
       "680                       Comedy|Drama|Romance  \n",
       "686                           Mystery|Thriller  \n",
       "690  Action|Adventure|Mystery|Romance|Thriller  \n",
       "692                               Comedy|Crime  \n",
       "841                                      Drama  \n",
       "903                   Action|Adventure|Western  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_movies_cf(user_id=1, model=model, ratings=ratings, movies=movies, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdffd511-f684-4e4a-8c38-9e648a5a4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def hybrid_recommend(user_id, movie_title, model, ratings, movies, top_n=10):\n",
    "    # --- Content-Based Filtering ---\n",
    "    # Build TF-IDF matrix for genres\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
    "\n",
    "    # Get the index of the given movie\n",
    "    idx = movies[movies['title'] == movie_title].index[0]\n",
    "\n",
    "    # Compute similarity of this movie to all others\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
    "\n",
    "    # Get top content-based movie indices\n",
    "    cb_indices = cosine_sim.argsort()[-50:][::-1]\n",
    "\n",
    "    # --- Collaborative Filtering ---\n",
    "    movie_scores = []\n",
    "    for i in cb_indices:\n",
    "        movie_id = movies.iloc[i]['movieId']\n",
    "        try:\n",
    "            pred_rating = model.predict(user_id, movie_id).est\n",
    "            score = (cosine_sim[i] + pred_rating) / 2  # Simple average\n",
    "            movie_scores.append((i, score))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Sort by combined score\n",
    "    movie_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_movies = [movies.iloc[i[0]][['title', 'genres']] for i in movie_scores[:top_n]]\n",
    "\n",
    "    return pd.DataFrame(top_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2f493c-b50b-4721-91fd-c00637067b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>Kiki's Delivery Service (Majo no takkyÃ»bin) (1...</td>\n",
       "      <td>Adventure|Animation|Children|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>Ponyo (Gake no ue no Ponyo) (2008)</td>\n",
       "      <td>Adventure|Animation|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>Inside Out (2015)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Watership Down (1978)</td>\n",
       "      <td>Adventure|Animation|Children|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy|Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Black Cauldron, The (1985)</td>\n",
       "      <td>Adventure|Animation|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>Kubo and the Two Strings (2016)</td>\n",
       "      <td>Adventure|Animation|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "5546  Kiki's Delivery Service (Majo no takkyÃ»bin) (1...   \n",
       "3568                              Monsters, Inc. (2001)   \n",
       "6944                 Ponyo (Gake no ue no Ponyo) (2008)   \n",
       "0                                      Toy Story (1995)   \n",
       "2355                                 Toy Story 2 (1999)   \n",
       "8900                                  Inside Out (2015)   \n",
       "1596                              Watership Down (1978)   \n",
       "3194                                       Shrek (2001)   \n",
       "1505                         Black Cauldron, The (1985)   \n",
       "9369                    Kubo and the Two Strings (2016)   \n",
       "\n",
       "                                                 genres  \n",
       "5546         Adventure|Animation|Children|Drama|Fantasy  \n",
       "3568        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "6944               Adventure|Animation|Children|Fantasy  \n",
       "0           Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2355        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "8900  Adventure|Animation|Children|Comedy|Drama|Fantasy  \n",
       "1596         Adventure|Animation|Children|Drama|Fantasy  \n",
       "3194  Adventure|Animation|Children|Comedy|Fantasy|Ro...  \n",
       "1505               Adventure|Animation|Children|Fantasy  \n",
       "9369               Adventure|Animation|Children|Fantasy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_recommend(user_id=1, movie_title=\"Toy Story (1995)\", model=model, ratings=ratings, movies=movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50cd71-24c0-4d63-b86f-4957069f89a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
